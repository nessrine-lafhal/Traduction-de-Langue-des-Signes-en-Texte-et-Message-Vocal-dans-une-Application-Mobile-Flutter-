
## Traduction de Langue des Signes en Texte et Message Vocal dans une Application Mobile Flutter
Ce projet vise à développer une application mobile capable de traduire la langue des signes en texte et en messages vocaux. L'application utilise des techniques avancées de traitement d'images et d'apprentissage automatique pour reconnaître les gestes de la langue des signes et les convertir en texte. Cette initiative a pour objectif d'améliorer l'accessibilité et la communication pour les personnes sourdes ou malentendantes.

## Technologies Utilisées
# Flutter

Description : Flutter est un framework open-source développé par Google pour la création d'applications mobiles multiplateformes. Il permet de concevoir des interfaces utilisateur fluides et réactives.
Rôle dans le projet : Flutter est utilisé pour le développement de l'interface utilisateur de l'application, offrant une expérience utilisateur agréable et intuitive.
# Dart

Description : Dart est le langage de programmation utilisé par Flutter. Il est orienté objet et optimisé pour le développement d'applications.
Rôle dans le projet : Dart est utilisé pour écrire la logique de l'application, gérer les états, et établir la communication avec le backend.
# Flask

Description : Flask est un framework web léger en Python qui facilite la création d'applications web.
Rôle dans le projet : Flask est utilisé pour développer le backend de l'application. Il gère les requêtes API, traite les données et communique avec les modèles de machine learning.
# Vision par Ordinateur

Description : Ensemble de techniques permettant aux ordinateurs de comprendre et d'interpréter des images.
Rôle dans le projet : La vision par ordinateur est utilisée pour analyser les vidéos et images des gestes de la langue des signes, permettant ainsi de les traduire en texte.
# Modèles de Machine Learning

Description : Techniques d'intelligence artificielle permettant de prédire des résultats basés sur des données.
Rôle dans le projet : Des modèles tels que les Réseaux de Neurones Convolutifs (CNN), LSTM, et Random Forest sont utilisés pour la reconnaissance des gestes et la traduction en texte.
# Émulateur

Description : Logiciel permettant de simuler un appareil mobile sur un ordinateur.
Rôle dans le projet : L'émulateur est utilisé pour tester et déboguer l'application pendant le développement.
# Bibliothèques et Packages

Description : Ensemble d'outils et de ressources utilisées pour faciliter le développement.
Rôle dans le projet : Divers packages sont intégrés pour améliorer les fonctionnalités de l'application, comme le traitement audio, l'analyse d'images, et la gestion des données.

# Conclusion
Ce projet innovant a pour but de rendre la communication plus accessible pour les personnes sourdes et malentendantes. En utilisant des technologies modernes comme Flutter et des techniques avancées de machine learning, nous visons à créer une application qui non seulement répond aux besoins des utilisateurs, mais qui ouvre également la voie à des améliorations futures dans ce domaine.


# test

![test1](https://github.com/nessrine-lafhal/Traduction-de-Langue-des-Signes-en-Texte-et-Message-Vocal-dans-une-Application-Mobile-Flutter-/blob/master/pic1.png)
![test1](https://github.com/nessrine-lafhal/Traduction-de-Langue-des-Signes-en-Texte-et-Message-Vocal-dans-une-Application-Mobile-Flutter-/blob/master/page%20d%20acceuil.png)




